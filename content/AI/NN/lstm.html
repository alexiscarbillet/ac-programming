<!DOCTYPE html>
<html lang="en">
  <head>
    <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-9364684337389377"
     crossorigin="anonymous"></script>

    

    

    


    <meta charset="utf-8">
    <title>Long Short-Term Memory</title>
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta name="description" content="What is Long Short-Term Memory? How to implement it in python?">
    <meta name="keywords" content="alexis carbillet, carbillet, artificial intelligence, python, neural network, Long Short-Term Memory">
    <meta name="author" content="Alexis Carbillet ">
 
    <!-- Control appearance when share by social media -->
    <meta property="og:title" content="What is Long Short-Term Memory?" />
    <meta property="og:description" content="What is Long Short-Term Memory? How to implement it in python?" />
    <meta property='og:url' content="https://coding.alexis-carbillet.com/content/NN/lstm.html" />
    <meta property="og:type" content="website" />

    <!-- Bootstrap core CSS -->
    <link href="../../../vendor/bootstrap/css/bootstrap.min.css" rel="stylesheet">

	<!-- Icon -->
	<link rel="shortcut icon" href="../../../img/logo/logo.png" />
	
    <!-- Custom fonts for this template -->
    <link href="../../../vendor/font-awesome/css/font-awesome.min.css" rel="stylesheet" type="text/css">
    <link href="https://fonts.googleapis.com/css?family=Montserrat:400,700" rel="stylesheet" type="text/css">
    <link href='https://fonts.googleapis.com/css?family=Kaushan+Script' rel='stylesheet' type='text/css'>
    <link href='https://fonts.googleapis.com/css?family=Droid+Serif:400,700,400italic,700italic' rel='stylesheet' type='text/css'>
    <link href='https://fonts.googleapis.com/css?family=Roboto+Slab:400,100,300,700' rel='stylesheet' type='text/css'>

    <!-- Custom styles for this template -->
    <link href="../../../css/structure.css" rel="stylesheet">

	<!-- Choice of languages -->
	<link rel="alternate" hreflang="x-default" href="https://coding.alexis-carbillet.com/" />


  </head>

  <body id="page-top">
    

    






    <!-- Navigation --> 
    <nav class="navbar navbar-expand-lg fixed-top" id="mainNav">
      <div class="container">
		<img src="../../../img/logo/logo.png" width="5%" style="margin-right: 2%;" alt="">
		<button class="navbar-toggler navbar-toggler-right" type="button" data-toggle="collapse" data-target="#navbarResponsive" aria-controls="navbarResponsive" aria-expanded="false" aria-label="Toggle navigation">
          <i class="fa fa-bars"></i>
        </button>
        <div class="collapse navbar-collapse" id="navbarResponsive">
          <ul class="navbar-nav text-uppercase ml-auto">
			<li class="nav-item">
              <a class="nav-link js-scroll-trigger" href="#article">Article</a>
            </li>
			<li class="nav-item">
              <a class="nav-link js-scroll-trigger" href="#python">Python example</a>
            </li>
            <li class="nav-item">
              <a class="nav-link js-scroll-trigger" href="#contact">Contact</a>
            </li>
			<li class="nav-item">
              <a class="nav-link js-scroll-trigger" href="../../../index.html#advanced">Main</a>
            </li>
          </ul>
        </div>
      </div>
    </nav>



    <!-- Header -->
    <header class="masthead">
	  <div class="container">		
		  
	  </div>
    </header>
	
<!-- ======================== ARTICLE SECTION ============================ -->

	<section id="article">
      <div class="container">
        <div class="row">
		  <div class="col-xs-12 col-md-12 col-sm-12 col-lg-12 text-center">
			<h2 class="section-heading text-uppercase">Long Short-Term Memory</h2>
		  </div>
		  <div class="col-xs-12 col-md-12 col-sm-12 col-lg-12 text-left">
		  <p>LSTM stands for Long Short-Term Memory, and it's a type of neural network that is particularly good at understanding and remembering patterns over long sequences of data.</p>
		  <p>Imagine you're trying to predict the next word in a sentence. In a traditional neural network, the network would look at each word in the sentence one by one and make predictions based on that word alone. However, this approach can be limiting because it doesn't take into account the context or the dependencies between different words.</p>
		  <p>This is where LSTM comes in. It's designed to address this problem by allowing the network to remember important information from earlier parts of the sentence and use it to make better predictions. Think of it as a memory system within the network.</p>
		  <p>LSTMs have a special structure called a cell, which consists of different components working together. One of the main components is called the "cell state," which is responsible for keeping track of the information the network has seen so far. It can selectively forget or add new information to this cell state.</p>
		  <p>Another important component is called the "gate." Gates control the flow of information within the LSTM cell. There are three types of gates: the forget gate, the input gate, and the output gate. Each gate has its own purpose.</p>
		  <p>The forget gate decides which information from the previous cell state should be discarded. It looks at the current input and the information from the previous time step and determines what is important to remember and what can be forgotten.</p>
		  <p>The input gate determines which new information should be stored in the cell state. It looks at the current input and decides which parts of the input are important to remember.</p>
		  <p>The output gate determines what information from the cell state should be outputted as the final prediction. It considers the current input and the cell state and decides what is relevant for the current prediction.</p>
		  <p>By using these gates and the cell state, LSTMs can selectively remember or forget information from the past, allowing them to capture long-term dependencies in the data. This makes them well-suited for tasks like speech recognition, language translation, and even generating text.</p>
		  <p>In simple terms, you can think of an LSTM as a smart network that can remember important things from the past and use that knowledge to make better predictions about the future.</p>
		  </div>
		</div>
      </div>
    </section>

<!-- ======================================================================= -->

<!-- ======================== PYTHON SECTION ============================ -->

	<section class="bg-light" id="python">
      <div class="container">
        <div class="row">
		  <div class="col-xs-12 col-md-12 col-sm-12 col-lg-12 text-center">
			<h2 class="section-heading text-uppercase">Python Example</h2>
		  </div>
		  <div class="col-xs-12 col-md-12 col-sm-12 col-lg-12 text-left">
			<pre><code>import numpy as np
from keras.models import Sequential
from keras.layers import LSTM, Dense

# Define your training data
X_train = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])
y_train = np.array([0, 1, 1, 0])

# Define the LSTM model
model = Sequential()
model.add(LSTM(4, input_shape=(2, 1)))  # 2 is the number of features, 1 is the time step
model.add(Dense(1, activation='sigmoid'))

# Compile the model
model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])

# Train the model
model.fit(np.expand_dims(X_train, axis=2), y_train, epochs=1000, batch_size=1)

# Test the model
X_test = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])
predictions = model.predict(np.expand_dims(X_test, axis=2))

# Print the predictions
print(predictions)</code></pre>
			<p>Predictions:</p>
      <pre><code>[[0.5152121 ]
[0.7969701 ]
[0.9556883 ]
[0.03418577]]</code></pre>
			<p>In this example, we are training an LSTM model to learn the XOR logic gate. The X_train consists of the input pairs (0, 0), (0, 1), (1, 0), and (1, 1), and the y_train represents their respective XOR outputs (0, 1, 1, 0).</p>
			<p>The model is defined using the Sequential API from Keras. We add an LSTM layer with 4 units and specify the input shape as (2, 1), indicating that we have 2 features (the two inputs) and a time step of 1. Then, we add a Dense layer with 1 unit and a sigmoid activation function to produce the final output.</p>
			<p>The model is compiled with the binary cross-entropy loss function, the Adam optimizer, and we also track the accuracy metric.</p>
			<p>We train the model using model.fit(), passing in the training data X_train and y_train. The model is trained for 1000 epochs with a batch size of 1.</p>
			<p>Finally, we test the model by passing the test data X_test through the model using model.predict(). The predictions are printed to the console.</p>
			<p>This example demonstrates how an LSTM can be used to learn and predict non-linear patterns in sequential data.</p>
		  </div>
		</div>
      </div>
    </section>

<!-- ======================================================================= -->

<!-- ========================== CONTACT SECTION ============================== -->

<iframe id="contact" src="../../../contact.html"  frameborder="0" scrolling="no" style="border: none; width: 100%; height: 140vh; max-height: 800px;"></iframe>

<!-- ======================================================================= -->


<!-- ======================= FOOTER SECTION ================================ -->
    <footer>
      <div class="container">
        <div class="row">
			<div class="col-xs-3 col-md-3 col-sm-3 col-lg-3">
        <iframe src="../../../copyright.html" frameborder="0" style="padding: 0%; max-height: 25px;"></iframe>
			</div>
			<div class="col-xs-6 col-md-6 col-sm-6 col-lg-6 text-center">
			</div>
			<div class="col-xs-1 col-md-1 col-sm-1 col-lg-1"></div>
			<div class="col-xs-2 col-md-2 col-sm-2 col-lg-2">
			<a href="../../../index.html"><span class="copyright" style="margin-right: 2%;">Blog</span></a>
			</div>
		</div>
		<div id="particles-js" style="height:50px;"></div>
      </div>
    </footer>

<!-- ======================================================================= -->

<!-- ======================== JAVASCRIPT SECTION =========================== -->



    <!-- Bootstrap core JavaScript -->
    <script src="../../../vendor/jquery/jquery.min.js"></script>
	<script src="../../../vendor/bootstrap/js/bootstrap.bundle.min.js"></script>

    <!-- Plugin JavaScript -->
    <script src="../../../vendor/jquery-easing/jquery.easing.min.js"></script>
	
    <!-- Custom scripts for this template -->
    <script src="../../../js/structure.js"></script>
	
	<!-- Particles part -->
	<script src="../../../js/particles.js"></script>
	<script src="../../../js/app.js"></script>
	
    <!-- Activate the bootstrap tooltip, must be after jQuery load -->
    <script>
    $(function () {
      $('[data-toggle="tooltip"]').tooltip();
    })
    </script>
	

<!-- ======================================================================= -->
  </body>

</html>
