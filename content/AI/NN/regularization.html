<!DOCTYPE html>
<html lang="en">
  <head>

    <meta charset="utf-8">
    <title>Regularization</title>
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta name="description" content="What is regularization for neural networks? How to implement it in python?">
    <meta name="keywords" content="alexis carbillet, carbillet, artificial intelligence, python, neural network, regularization">
    <meta name="author" content="Alexis Carbillet ">
 
    <!-- Control appearance when share by social media -->
    <meta property="og:title" content="What is regularization for neural networks?" />
    <meta property="og:description" content="What is regularization for neural networks? How to implement it in python?" />
    <meta property='og:url' content="https://www.ac-programming.com/content/NN/regularization.html" />
    <meta property="og:type" content="website" />

    <!-- Bootstrap core CSS -->
    <link href="../../../vendor/bootstrap/css/bootstrap.min.css" rel="stylesheet">

	<!-- Icon -->
	<link rel="shortcut icon" href="../../../img/logo/logo.png" />
	
    <!-- Custom fonts for this template -->
    <link href="../../../vendor/font-awesome/css/font-awesome.min.css" rel="stylesheet" type="text/css">
    <link href="https://fonts.googleapis.com/css?family=Montserrat:400,700" rel="stylesheet" type="text/css">
    <link href='https://fonts.googleapis.com/css?family=Kaushan+Script' rel='stylesheet' type='text/css'>
    <link href='https://fonts.googleapis.com/css?family=Droid+Serif:400,700,400italic,700italic' rel='stylesheet' type='text/css'>
    <link href='https://fonts.googleapis.com/css?family=Roboto+Slab:400,100,300,700' rel='stylesheet' type='text/css'>

    <!-- Custom styles for this template -->
    <link href="../../../css/structure.css" rel="stylesheet">

	<!-- Choice of languages -->
	<link rel="alternate" hreflang="x-default" href="https://www.ac-programming.com/" />


  </head>

  <body id="page-top">





    <!-- Navigation --> 
    <nav class="navbar navbar-expand-lg fixed-top" id="mainNav">
      <div class="container">
		<img src="../../../img/logo/logo.png" width="5%" style="margin-right: 2%;" alt="">
		<button class="navbar-toggler navbar-toggler-right" type="button" data-toggle="collapse" data-target="#navbarResponsive" aria-controls="navbarResponsive" aria-expanded="false" aria-label="Toggle navigation">
          <i class="fa fa-bars"></i>
        </button>
        <div class="collapse navbar-collapse" id="navbarResponsive">
          <ul class="navbar-nav text-uppercase ml-auto">
			<li class="nav-item">
              <a class="nav-link js-scroll-trigger" href="#article">Article</a>
            </li>
			<li class="nav-item">
              <a class="nav-link js-scroll-trigger" href="#python">Comparison</a>
            </li>
            <li class="nav-item">
              <a class="nav-link js-scroll-trigger" href="#contact">Contact</a>
            </li>
			<li class="nav-item">
              <a class="nav-link js-scroll-trigger" href="../../../index.html#advanced">Main</a>
            </li>
          </ul>
        </div>
      </div>
    </nav>



    <!-- Header -->
    <header class="masthead">
	  <div class="container">		
		  
	  </div>
    </header>
	
<!-- ======================== ARTICLE SECTION ============================ -->

	<section id="article">
      <div class="container">
        <div class="row">
		  <div class="col-xs-12 col-md-12 col-sm-12 col-lg-12 text-center">
			<h2 class="section-heading text-uppercase">Regularization</h2>
		  </div>
		  <div class="col-xs-12 col-md-12 col-sm-12 col-lg-12 text-left">
		  <p>Let's start by understanding what overfitting is. When training a neural network, overfitting happens when the model becomes too specialized in the training data and fails to generalize well to new, unseen data. It's like memorizing the answers to specific questions without really understanding the underlying concepts.</p>
		  <p>Now, regularization comes into the picture to prevent overfitting. It's like adding a regular check on the model's learning process to ensure it doesn't get too carried away with the training data. Regularization techniques add extra terms or penalties to the neural network's loss function (a measure of how well the model performs). These penalties discourage the model from becoming overly complex and help it focus on more general patterns rather than specific noise or outliers in the data.</p>
		  <p>One common regularization technique is called L2 regularization, or weight decay. It works by adding a term to the loss function that penalizes large weights in the network. This encourages the model to use smaller weights, which can help prevent overfitting.</p>
		  <p>Another popular technique is called dropout. Dropout randomly turns off a fraction of the neurons in the network during training. By doing this, it forces the remaining neurons to become more robust and prevents them from relying too heavily on any specific input features.</p>
		  <p>Overall, regularization techniques act as a kind of control mechanism for neural networks, promoting simplicity and generalization, which in turn helps the model perform better on new, unseen data.</p>
		  </div>
		</div>
      </div>
    </section>

<!-- ======================================================================= -->

<!-- ======================== PYTHON SECTION ============================ -->

	<section class="bg-light" id="python">
      <div class="container">
        <div class="row">
		  <div class="col-xs-12 col-md-12 col-sm-12 col-lg-12 text-center">
			<h2 class="section-heading text-uppercase">Activations Comparison</h2>
		  </div>
		  <div class="col-xs-12 col-md-12 col-sm-12 col-lg-12 text-left">
			<p>Let's compare two popular regularization techniques: L1 regularization and L2 regularization.</p>
			<pre><p>
			L1 Regularization:

				L1 regularization, also known as Lasso regularization, adds a penalty term to the loss function that encourages the neural network to have sparse weights.
				It achieves sparsity by driving some of the weights to exactly zero, effectively eliminating some features from the model.
				L1 regularization can be useful for feature selection, as it automatically selects relevant features and discards irrelevant ones.
				However, L1 regularization tends to produce models with a smaller number of non-zero weights, which may result in a simpler model but could potentially sacrifice some predictive performance.

			L2 Regularization:

				L2 regularization, also known as Ridge regularization, adds a penalty term to the loss function that encourages the neural network to have small weights.
				It penalizes the square of the weights, which leads to a smoother distribution of weights across all the features.
				L2 regularization helps in preventing overfitting by discouraging large weight values, making the model more robust to noise and outliers.
				It does not lead to sparse solutions like L1 regularization, as the weights are only driven towards zero but not exactly zero.
				L2 regularization often improves the generalization performance of the model by reducing the influence of individual features without completely excluding them.
			</p></pre>
			<p>In summary, L1 regularization promotes sparsity and feature selection, while L2 regularization encourages small weights and smoother weight distributions. The choice between the two depends on the specific problem and the desired trade-off between model simplicity and predictive performance.</p>
		  </div>
		</div>
      </div>
    </section>

<!-- ======================================================================= -->

<!-- ========================== CONTACT SECTION ============================== -->

<iframe id="contact" src="../../../contact.html"  frameborder="0" scrolling="no" style="border: none; width: 100%; height: 140vh; max-height: 800px;"></iframe>

<!-- ======================================================================= -->


<!-- ======================= FOOTER SECTION ================================ -->
    <footer>
      <div class="container">
        <div class="row">
			<div class="col-xs-3 col-md-3 col-sm-3 col-lg-3">
        <iframe src="../../../copyright.html" frameborder="0" style="padding: 0%; max-height: 25px;"></iframe>
			</div>
			<div class="col-xs-6 col-md-6 col-sm-6 col-lg-6 text-center">
			</div>
			<div class="col-xs-1 col-md-1 col-sm-1 col-lg-1"></div>
			<div class="col-xs-2 col-md-2 col-sm-2 col-lg-2">
			<a href="../../../index.html"><span class="copyright" style="margin-right: 2%;">Blog</span></a>
			</div>
		</div>
		<div id="particles-js" style="height:50px;"></div>
      </div>
    </footer>

<!-- ======================================================================= -->

<!-- ======================== JAVASCRIPT SECTION =========================== -->



    <!-- Bootstrap core JavaScript -->
    <script src="../../../vendor/jquery/jquery.min.js"></script>
	<script src="../../../vendor/bootstrap/js/bootstrap.bundle.min.js"></script>

    <!-- Plugin JavaScript -->
    <script src="../../../vendor/jquery-easing/jquery.easing.min.js"></script>
	
    <!-- Custom scripts for this template -->
    <script src="../../../js/structure.js"></script>
	
	<!-- Particles part -->
	<script src="../../../js/particles.js"></script>
	<script src="../../../js/app.js"></script>
	
    <!-- Activate the bootstrap tooltip, must be after jQuery load -->
    <script>
    $(function () {
      $('[data-toggle="tooltip"]').tooltip();
    })
    </script>
	

<!-- ======================================================================= -->
  </body>

</html>
