<!DOCTYPE html>
<html lang="en">
  <head>
    <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-9364684337389377"
     crossorigin="anonymous"></script>

    

    

    


    <meta charset="utf-8">
    <title>Stochastic Gradient Descent</title>
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta name="description" content="What is stochastic gradient descent? How to implement it in python?">
    <meta name="keywords" content="alexis carbillet, carbillet, machine learning, supervised machine learning, artificial intelligence, python, Stochastic Gradient Descent">
    <meta name="author" content="Alexis Carbillet ">
 
    <!-- Control appearance when share by social media -->
    <meta property="og:title" content="What is stochastic gradient descent?" />
    <meta property="og:description" content="What is stochastic gradient descent? How to implement it in python?" />
    <meta property='og:url' content="https://www.ac-programming.com/content/SML/sgd.html" />
    <meta property="og:type" content="website" />

    <!-- Bootstrap core CSS -->
    <link href="../../../vendor/bootstrap/css/bootstrap.min.css" rel="stylesheet">

	<!-- Icon -->
	<link rel="shortcut icon" href="../../../img/logo/logo.png" />
	
    <!-- Custom fonts for this template -->
    <link href="../../../vendor/font-awesome/css/font-awesome.min.css" rel="stylesheet" type="text/css">
    <link href="https://fonts.googleapis.com/css?family=Montserrat:400,700" rel="stylesheet" type="text/css">
    <link href='https://fonts.googleapis.com/css?family=Kaushan+Script' rel='stylesheet' type='text/css'>
    <link href='https://fonts.googleapis.com/css?family=Droid+Serif:400,700,400italic,700italic' rel='stylesheet' type='text/css'>
    <link href='https://fonts.googleapis.com/css?family=Roboto+Slab:400,100,300,700' rel='stylesheet' type='text/css'>

    <!-- Custom styles for this template -->
    <link href="../../../css/structure.css" rel="stylesheet">

	<!-- Choice of languages -->
	<link rel="alternate" hreflang="x-default" href="https://www.ac-programming.com/" />


  </head>

  <body id="page-top">
    

    






    <!-- Navigation --> 
    <nav class="navbar navbar-expand-lg fixed-top" id="mainNav">
      <div class="container">
		<img src="../../../img/logo/logo.png" width="5%" style="margin-right: 2%;" alt="">
		<button class="navbar-toggler navbar-toggler-right" type="button" data-toggle="collapse" data-target="#navbarResponsive" aria-controls="navbarResponsive" aria-expanded="false" aria-label="Toggle navigation">
          <i class="fa fa-bars"></i>
        </button>
        <div class="collapse navbar-collapse" id="navbarResponsive">
          <ul class="navbar-nav text-uppercase ml-auto">
			<li class="nav-item">
              <a class="nav-link js-scroll-trigger" href="#article">Article</a>
            </li>
			<li class="nav-item">
              <a class="nav-link js-scroll-trigger" href="#python">Python example</a>
            </li>
            <li class="nav-item">
              <a class="nav-link js-scroll-trigger" href="#contact">Contact</a>
            </li>
			<li class="nav-item">
              <a class="nav-link js-scroll-trigger" href="../../../index.html#advanced">Main</a>
            </li>
          </ul>
        </div>
      </div>
    </nav>



    <!-- Header -->
    <header class="masthead">
	  <div class="container">		
		  
	  </div>
    </header>
	
<!-- ======================== ARTICLE SECTION ============================ -->

	<section id="article">
      <div class="container">
        <div class="row">
		  <div class="col-xs-12 col-md-12 col-sm-12 col-lg-12 text-center">
			<h2 class="section-heading text-uppercase">Stochastic Gradient Descent</h2>
		  </div>
		  <div class="col-xs-12 col-md-12 col-sm-12 col-lg-12 text-left">
		  <p>Stochastic Gradient Descent (SGD) is a popular optimization algorithm used in machine learning. It is used to train models by finding the best values for their parameters.</p>
		  <p>To understand SGD, let's first talk about Gradient Descent. Gradient Descent is a method for finding the minimum of a function. In the context of machine learning, this function represents the "error" or "loss" of a model, which measures how well the model is performing on a given task.</p>
		  <p>In traditional Gradient Descent, you calculate the gradient of the loss function with respect to each parameter of the model. The gradient tells you the direction in which the parameters should be updated to reduce the loss. You update the parameters by taking small steps in the opposite direction of the gradient until you reach a minimum.</p>
		  <p>Now, let's introduce the "stochastic" part of SGD. In Stochastic Gradient Descent, instead of calculating the gradient using the entire dataset, you calculate it on a single random example (or a small subset of examples) at each iteration. This randomness is what makes SGD "stochastic."</p>
		  <p>Why would we want to do that? Well, when working with large datasets, computing the gradient on the entire dataset can be computationally expensive. By using only a small subset or a single example, SGD significantly reduces the computational burden.</p>
		  <p>Moreover, SGD has a nice property: it introduces some randomness in the learning process. The random selection of examples can help the model avoid getting stuck in local minima (suboptimal solutions). It allows the model to explore different areas of the parameter space, potentially finding a better overall minimum.</p>
		  <p>However, there is a trade-off with this randomness. Since SGD uses only a subset of examples, the gradient it computes may not be as accurate as the one from traditional Gradient Descent. This introduces some noise in the optimization process. However, in practice, this noise is often tolerable and can even help the model generalize better to new, unseen data.</p>
		  <p>To summarize, Stochastic Gradient Descent is an optimization algorithm that updates the parameters of a model by computing the gradient of the loss function on a single random example or a small subset of examples. It is faster and more scalable for large datasets, introduces randomness to avoid local minima, but sacrifices some accuracy for faster computations.</p>
		  </div>
		</div>
      </div>
    </section>

<!-- ======================================================================= -->

<!-- ======================== PYTHON SECTION ============================ -->

	<section class="bg-light" id="python">
      <div class="container">
        <div class="row">
		  <div class="col-xs-12 col-md-12 col-sm-12 col-lg-12 text-center">
			<h2 class="section-heading text-uppercase">Python Example</h2>
		  </div>
		  <div class="col-xs-12 col-md-12 col-sm-12 col-lg-12 text-left">
			<pre><code>import numpy as np

# Generate some random training data
X = 2 * np.random.rand(100, 1)  # Input features
y = 4 + 3 * X + np.random.randn(100, 1)  # Target labels with noise

# Add bias term to input features
X_b = np.c_[np.ones((100, 1)), X]

# Set random seed for reproducibility
np.random.seed(42)

# Initialize random weights
theta = np.random.randn(2, 1)

# Set hyperparameters
learning_rate = 0.1
n_epochs = 100
m = len(X)

# Stochastic Gradient Descent
for epoch in range(n_epochs):
  for i in range(m):
    random_index = np.random.randint(m)  # Randomly select an example
    
    xi = X_b[random_index:random_index+1]
    yi = y[random_index:random_index+1]
    
    gradients = 2 * xi.T.dot(xi.dot(theta) - yi)  # Compute gradient
    theta = theta - learning_rate * gradients  # Update weights

# Print the learned parameters
print("Intercept:", theta[0][0])
print("Slope:", theta[1][0])</code></pre>
			<p>Results:</p>
      <pre><code>Intercept: 4.223113526238277
Slope: 2.734026492950525</code></pre>
			<p>In this example, we generate some random training data with a linear relationship between the input features (X) and the target labels (y). We add a bias term to the input features and initialize random weights.</p>
			<p>The Stochastic Gradient Descent loop iterates over a fixed number of epochs. For each epoch, it randomly selects a single example from the dataset. It computes the gradient of the loss function with respect to the weights using this example and updates the weights accordingly.</p>
			<p>At the end of the loop, the learned parameters (intercept and slope) are printed. These parameters represent the best-fit line that the Stochastic Gradient Descent algorithm has found to approximate the data.</p>
		  </div>
		</div>
      </div>
    </section>

<!-- ======================================================================= -->

<!-- ========================== CONTACT SECTION ============================== -->

<iframe id="contact" src="../../../contact.html"  frameborder="0" scrolling="no" style="border: none; width: 100%; height: 140vh; max-height: 800px;"></iframe>

<!-- ======================================================================= -->


<!-- ======================= FOOTER SECTION ================================ -->
    <footer>
      <div class="container">
        <div class="row">
			<div class="col-xs-3 col-md-3 col-sm-3 col-lg-3">
        <iframe src="../../../copyright.html" frameborder="0" style="padding: 0%; max-height: 25px;"></iframe>
			</div>
			<div class="col-xs-6 col-md-6 col-sm-6 col-lg-6 text-center">
			</div>
			<div class="col-xs-1 col-md-1 col-sm-1 col-lg-1"></div>
			<div class="col-xs-2 col-md-2 col-sm-2 col-lg-2">
			<a href="../../../index.html"><span class="copyright" style="margin-right: 2%;">Blog</span></a>
			</div>
		</div>
		<div id="particles-js" style="height:50px;"></div>
      </div>
    </footer>

<!-- ======================================================================= -->

<!-- ======================== JAVASCRIPT SECTION =========================== -->



    <!-- Bootstrap core JavaScript -->
    <script src="../../../vendor/jquery/jquery.min.js"></script>
	<script src="../../../vendor/bootstrap/js/bootstrap.bundle.min.js"></script>

    <!-- Plugin JavaScript -->
    <script src="../../../vendor/jquery-easing/jquery.easing.min.js"></script>
	
    <!-- Custom scripts for this template -->
    <script src="../../../js/structure.js"></script>
	
	<!-- Particles part -->
	<script src="../../../js/particles.js"></script>
	<script src="../../../js/app.js"></script>
	
    <!-- Activate the bootstrap tooltip, must be after jQuery load -->
    <script>
    $(function () {
      $('[data-toggle="tooltip"]').tooltip();
    })
    </script>
	

<!-- ======================================================================= -->
  </body>

</html>
